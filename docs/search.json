[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Flywheels and Public AI",
    "section": "",
    "text": "Preface\nThis is a ‚Äúmini-book‚Äù that discusses ‚Äúpublic AI flywheels‚Äù: software meant to enable people to opt-in to contribute data towards ‚Äúpublic AI‚Äù causes. The goal of this book is to support efforts build a transparent, people-centric data collection ecosystem that supports the evaluation and training of public-benefit AI models. More frankly, this is way to organize some design notes, practical documentation that‚Äôs out of scope for a single example projec‚Äôs repo, and longer abstract writing on the topic.\nThis document is organized as such:\n\nIn Section 1 (current section), we first we describe how this document is organized and introduce the Public AI Flywheel concept.\n\nSection 1.2 describes ‚Äúcore principles‚Äù for a public AI data flywheel\n\nIn Section 2, we discuss one particular implementation of a Minimum Viable Product (MVP) opt-in flywheel meant to accompany a ‚Äúpublic AI interface‚Äù (hosted interface software that hits various endpoints for ‚Äúpublic AI models‚Äù) that uses a ‚Äúserverless‚Äù app + Git backend approach\n\nThis MVP focuses on collecting two high-signal data types: exports of ‚Äúgood chats‚Äù and ‚Äúfail chats.‚Äù This data provides immediate value for model evaluation and, at scale, can be used for fine-tuning. Importantly, collecting a list of good and bad chats is also immediately fun, so contributors can get some value before we reach a threshold of data volume needed to construct a full benchmark or dataset. We expect key ideas discussed in this doc, and concretized in this project, to generalize to other data types.\n\nIn Section 3, we provide details on the data retention policy for the Public AI Flywheel and the data policy for the full public AI interface pipeline: from model endpoints to OpenWebUI interface to flywheel platform.\nIn Section 4, we explore the design space in much more detail, describing many other ways that flywheels could be implemented (with the hope of providing a helpful starting point, but also providing more rationale around our MVP)",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01intro.html",
    "href": "01intro.html",
    "title": "1¬† Introduction",
    "section": "",
    "text": "1.1 Definitions\nWhat is a data flywheel? Nvidia gives us this definition: ‚ÄúA data flywheel is a feedback loop where data collected from interactions or processes is used to continuously refine AI models.‚Äù Others have also written on data flywheels (see e.g.¬†a number of helpful blogs from Roche and Sasson, Liu and Del Balso.\nWhat is public AI? The public AI network gives us this: AI with\nFor more on the public AI concept, see also Mozilla‚Äôs work in this space and several workshop papers and preprints (from RegML 2023 at NeurIPS, CodeML 2025 at ICML).\nOur focus in this mini-book is in building public AI flywheels.In order to achieve public access and accountability, public AI systems must also face some unique challenges around the implementation of data flywheels ‚Äì they may not be able to do what private orgs can do.\nWe are trying to create a feedback loop to improve AI: but we want to start from a position of accessibility (including providing an accessible explanation of exactly what happens to data) and accountability (so people have real agency over data).\nOf course, it‚Äôs worth noting that a given public could deliberate and make a collective decision that they prefer an more ‚Äútraditional approach‚Äù to data. Here, we are taking the stance that it‚Äôs best to start from a position of leaning heavily towards an opt-in approach (minimize usage and retention of data; data that is used in the flywheel to train AI should be provided via an opt-in by highly informed users).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01intro.html#definitions",
    "href": "01intro.html#definitions",
    "title": "1¬† Introduction",
    "section": "",
    "text": "‚ÄúPublic Access ‚Äì Certain capabilities are so important for participation in public life that access to them should be universal. Public AI provides affordable access to these tools so that everyone can realize their potential.‚Äù ‚ÄúPublic Accountability ‚Äì Public AI earns trust by ensuring ultimate control of development rests with the public, giving everyone a chance to participate in shaping the future.‚Äù ‚ÄúPermanent Public Goods ‚Äì Public AI is funded and operated in a way to maintain the public goods it produces permanently, enabling innovators to safely build on a firm foundation.‚Äù",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01intro.html#core-principles",
    "href": "01intro.html#core-principles",
    "title": "1¬† Introduction",
    "section": "1.2 Core Principles",
    "text": "1.2 Core Principles\nTranslating the core principles of public AI to the data flywheel domain (and to data strategy more generally), we aim to adhere to the following non-negotiable principles:\n\nTransparency & Informed Consent: Users must be fully informed about the model, its developer, and the ramifications of their contribution. A detailed FAQ and a clear consent module are required before any data is shared. To some extent, true transparency and informed consent requires to active expenditure of resoures to improve the public‚Äôs AI literary. We need systems that really do inform people (luckily, that‚Äôs something it seems like AI can be good for).\nUser Control & Data Rights The system must empower users with control over their data, mirroring GDPR principles. This includes the right to access ($Art. 15$), rectify ($Art. 16$), erase ($Art. 17$), and port their data ($Art. 20$). Key exemplar: Mozilla Common Voice).\n\nWe note that user control and data rights sometimes conflict with a ‚Äúfully open‚Äù ethos; we will attempt to mitigate these tensions to the best extent possible!\n\nPrivacy and options for pseudonymity: To the extent possible, we believe it is valuable to offer people to ability to contribute to data flywheel with their ‚Äúreal account‚Äù attached (to earn credit and reputation), but also to maintain an option to use ‚Äúlight-auth‚Äù system, requiring only an email (or similar) for authentication via passwordless magic links. If users take this approach, public contributions will be attributed to a randomly generated handle (e.g., ‚Äúsilver-badger-81‚Äù) to protect people‚Äôs identity. However, in our MVP (discussed in the next chapter) a HuggingFace account is required to make contributions, but users can choose to remain anonymous or use a pseudonym for the public data release.\nPurpose Limitation & Licensing: Users must be able to specify their preferences for how their data is used (e.g., for public display and evaluation vs.¬†for model training). This is captured using (new) IETF AI Use Preferences and Creative Commons Preference Signals. We will discuss below how this might extend to other preference signal proposals and/or technical approaches to gating data.\n\nThis is critical for answering a likely FAQ around public AI data ‚Äì if you succeed in creating actually useful training data or new benchmarks, won‚Äôt private labs just immediately use that dat as well?",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02mvp.html",
    "href": "02mvp.html",
    "title": "2¬† The Serverless + Git MVP",
    "section": "",
    "text": "2.1 Overview\nOur initial MVP of the flywheel is a ‚ÄúServerless + Git Platform‚Äù approach. It is meant to be a robust and scalable starting point for the data flywheel. It strictly separates the ‚Äúwrite‚Äù (contribution) and ‚Äúread‚Äù (display) components of the system.\nThe overall goal is to enable opt-in contributions of data (prompt/output + optional metadata) with the state-of-the-art (caveat: also experimental / untested) preference signals and enforcement via per-item Creative Commons license (in MVP: default is CC0, CC-BY, CC-BY-SA) and an AI preference signal (using IETF aipref draft spec + CC Preference Signals draft spec). The data is distributed via:\nFor full details, see the separate repo and its readme: #todo fill me in\nFor a short summary of the technical approach, see below bullet point:",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Serverless + Git MVP</span>"
    ]
  },
  {
    "objectID": "02mvp.html#overview",
    "href": "02mvp.html#overview",
    "title": "2¬† The Serverless + Git MVP",
    "section": "",
    "text": "Hugging Face (gated) ‚Äî full bundles by license bucket; access via request/terms; HF workflows used for deletions where possible.\nPublic site ‚Äî leaderboards + full dataset access; Cloudflare WAF/bot controls to discourage bulk scraping.\n\n\n\n\nFrontend: A Next.js application hosted on Vercel, providing a simple, static interface for contributions.\n\nNo major lock-in here. Can easily be swapped for a lightweight static site, other modern web tech, etc.\n\nAuthentication: User identity is managed via Auth.js (Next-Auth), using Hugging Face (HF) as the exclusive OAuth provider. This allows for clear attribution of contributions to a user‚Äôs public HF username (if they choose to).\nData Storage: The single source of truth is a Hugging Face Dataset repository, which functions as a ‚ÄúGit-as-a-database.‚Äù\n\nStarting with HF as it is a platform with specific focus on AI datasets and open culture\n\nWaiting room approach: The implemented workflow follows a two-stage ‚Äúwaiting room‚Äù pattern to ensure data quality and safety:\nHow contribution works:\n\nA user logs in with their Hugging Face account.\nThe interface accepts contributions in three ways: by uploading an OpenWebUI JSON export file, via URL params, or by pasting plain text.\nThe frontend parser automatically detects the OpenWebUI format, extracts metadata (like model and tags), and prepends it as YAML frontmatter to the chat content.\nUsers choose a label for the chat type (‚ÄúGood Chat‚Äù / ‚ÄúFail Chat‚Äù) and attach (1) a Creative Commons license and (2) an IETF aipref and/or Creative Commons Preference Signal to signal preferences around AI use of the contribution.\nA pseudo-anonymity system allows users to contribute publicly with their HF username, as ‚Äúanonymous,‚Äù or with a custom pseudonym.\nAn informed consent checkbox, linked to Terms of Service and FAQ pages, is required for all submissions.\nUpon submission, a serverless function writes the contribution not to the final dataset, but as a new, single JSON file in a _waiting_room/ directory within the Hugging Face repository. This operation is fast and avoids write conflicts.\n\nHow processing of the ‚Äúwaiting room‚Äù works:\n\nA separate, asynchronous script is run on a regular schedule (e.g., as a daily GitHub Action).\nThis script fetches all pending files from the _waiting_room.\nIt validates each contribution and includes a placeholder for future content moderation and PII checks.\nValidated contributions are batched and appended to a final, organized dataset file (e.g., data/2025-08.jsonl). Contributions are further bucketed by license/prefs.\nTo ensure atomicity, all file additions (to the final dataset) and deletions (from the waiting room) are performed in a single commit to the Hugging Face Hub. #todo when scaling, need to consider race conditions around the processing!",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Serverless + Git MVP</span>"
    ]
  },
  {
    "objectID": "02mvp.html#advantages-of-a-serverless-git-approach",
    "href": "02mvp.html#advantages-of-a-serverless-git-approach",
    "title": "2¬† The Serverless + Git MVP",
    "section": "2.2 Advantages of a Serverless + Git approach",
    "text": "2.2 Advantages of a Serverless + Git approach\nA serverless + Git stack keeps the ‚Äúwrite path‚Äù lightweight for contributors and cheap to operate. Functions spin up on demand and idle to zero, so we can avoid paying for boxes that sit around; the trade-off is cold starts, which are well-documented and can be mitigated with provisioned concurrency when needed.\nOn the ‚Äúread path,‚Äù a static site on a global CDN gives instant distribution and low operational overhead. Pages (e.g., from Cloudflare, something like GitHub Pages, or similar) can read directly from the Git ‚Äúsource of truth‚Äù and serve assets from edge locations by default, which is exactly what we want for a browsable leaderboard and dataset browser.\nAdditionally, using the Hub (Git-backed) as the source of truth buys us a public audit trail and first-class versioning semantics. HF‚Äôs dataset repos are literally Git + LFS, with revision pinning via commit/tag/branch; storage is backed by object storage and scales. That maps cleanly to our ‚Äúwaiting room ‚Üí release buckets‚Äù workflow and makes it easy to diff changes over time. (relevant HF docs: datasets, storage)\nModeration and PII handling are naturally centralized in the processing step. Because we trigger the write as a small file into a staging path and move it during a scheduled job, we can run filters, de-dup, and attach license/pref metadata before publication without asking contributors to learn tooling.\nBasic safety and access controls are pragmatic at the edge. Cloudflare‚Äôs WAF/Bot Management and newer ‚ÄúAI bot‚Äù controls give us a reasonable anti-scraping posture for public downloads and pages, even if nothing on the open web is truly copy-proof. Recent product updates explicitly target AI crawlers, with default blocking and challenge flows we can enable. (Cloudflare Docs, WIRED, Business Insider)\nFinally, the ‚Äúpreferences and licenses‚Äù story fits the stack. Dataset cards and metadata natively expose a license field and other tags (Hub UI and YAML), and CC licenses give clear obligations (e.g., BY, BY-SA) we can enforce in packaging and docs. That lets us partition releases by license and publish compatibility notes in a way downstream users can actually follow. (Hugging Face, Hugging Face)",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Serverless + Git MVP</span>"
    ]
  },
  {
    "objectID": "02mvp.html#disadvantages-and-what-to-watch",
    "href": "02mvp.html#disadvantages-and-what-to-watch",
    "title": "2¬† The Serverless + Git MVP",
    "section": "2.3 Disadvantages (and what to watch)",
    "text": "2.3 Disadvantages (and what to watch)\nTrust centralizes in the processor. Contributors have to believe the middle layer won‚Äôt silently drop or reshape submissions. If/when we introduce event-driven ingestion (queues/streams), we must design for retries and duplicates.\nUX isn‚Äôt perfectly ‚Äúinstant.‚Äù There‚Äôs an inherent gap between a user pressing ‚Äúshare‚Äù and seeing their item on the public site, because we run validation and batching. That‚Äôs a conscious choice, but we should set expectations and likely provide some kind status expectations.\nOperationally, serverless isn‚Äôt ‚Äúno ops,‚Äù it‚Äôs ‚Äúdifferent ops.‚Äù Cold starts exist (especially on sporadic paths), API limits are real on the platforms we hit (GitHub has documented ceilings; HF also rate-limits writes/reads even if specifics vary by endpoint), and ‚Äúpay per use‚Äù can surprise us at scale without cost guardrails (see e.g.¬†GitHub Docs, GitHub Docs).\nThere‚Äôs also platform coupling to be consider. Using specific hosted CI/CD, serverless runtimes, and hub APIs creates a degree of vendor lock-in; this is a known trade-off in serverless architectures and something we can blunt with portable formats (JSONL), documented exports, and ‚Äúboring‚Äù interfaces (Git). ([CNCF][17])\nCompliance remains non-zero. Deletions across mirrored artifacts (Hub revisions, static site snapshots, downstream forks) take a clear policy and a repeatable playbook. For licenses, we‚Äôre responsible for honoring CC obligations in our packaging and comms (e.g., keeping BY attribution fields intact; not mixing BY-SA content into incompatible bundles). CC‚Äôs legalcode and guidance make those obligations explicit; our tooling should, too. (Creative Commons)\nNet: Serverless + Git gives us a pragmatic bridge‚Äîfast contributor UX, public versioning, cheap distribution‚Äîwhile we invest in moderation, idempotent processors, and clear license lanes. If we communicate the review gap, publish the processor‚Äôs rules, and keep escape hatches (export scripts, mirrors), the trade-offs are acceptable for an MVP and refine-able over time.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Serverless + Git MVP</span>"
    ]
  },
  {
    "objectID": "02mvp.html#other-reading",
    "href": "02mvp.html#other-reading",
    "title": "2¬† The Serverless + Git MVP",
    "section": "2.4 Other reading:",
    "text": "2.4 Other reading:\n\nhttps://arxiv.org/abs/2109.02846\nhttps://datascience.codata.org/articles/10.5334/dsj-2021-012",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Serverless + Git MVP</span>"
    ]
  },
  {
    "objectID": "03data_policy.html",
    "href": "03data_policy.html",
    "title": "3¬† Data Flow and Data Retention",
    "section": "",
    "text": "4 Glossary of Defined Terms (for this Chapter)\n‚Äú{The Public AI Chat Frontend}‚Äù or ‚ÄúFrontend‚Äù means the hosted interface described in this document that allows users to issue prompts to third-party model endpoints.\n‚ÄúOpen WebUI Instance‚Äù or ‚ÄúOWUI‚Äù means the hosted Open WebUI application at {{app_link}} (or successor URLs) that provides optional accounts and chat history.\n‚ÄúOpt-in Data Flywheel‚Äù or ‚ÄúFlywheel‚Äù means the separate contribution and distribution platform at https://optinflywheel.com (or successor URLs) through which users may opt in to contribute data for public evaluation and research use.\n‚ÄúProvider(s)‚Äù or ‚ÄúModel Endpoint(s)‚Äù means third-party model services (e.g., national labs, commercial providers) that receive user prompts and return model outputs. The Frontend is a gateway to these services and does not control their retention, training, or use practices.\n‚ÄúModel Gateway‚Äù means the service layer that forwards requests from the Frontend to Providers and records a Request Envelope (metadata such as request ID, model ID, token counts, latency, and status).\n‚ÄúRequest Envelope‚Äù means non-content request metadata retained for reliability, capacity, and SLO monitoring.\n‚ÄúSession Telemetry‚Äù means minimal first-party analytics collected on page load/navigation (e.g., timestamp, pseudonymous session ID, coarse locale, feature flags).\n‚ÄúSecurity Logs‚Äù means IP address and User-Agent records used for rate-limiting and abuse detection.\n‚ÄúChat Object‚Äù means prompt(s), tool calls (if any), and model output(s) associated with a session or account within the Open WebUI Instance.\n‚ÄúContribution‚Äù means any data a user intentionally submits to the Flywheel (e.g., prompt/output pairs, tags, corrections), along with per-item License and AI Preference Signal selections.\n‚ÄúAI Preference Signal‚Äù means an AI-use preference value the contributor attaches to a Contribution (e.g., IETF AI Preferences draft values and/or Creative Commons preference signals), intended to be conveyed downstream.\n‚ÄúLicense‚Äù means the Creative Commons license selected by the contributor for a Contribution (supported in the MVP: CC0-1.0, CC-BY-4.0, CC-BY-SA-4.0).\n‚ÄúLicense Bucket(s)‚Äù means the partitioning of Contributions into separate release artifacts by License (e.g., v1.0-cc0, v1.0-cc-by, v1.0-cc-by-sa).\n‚ÄúWaiting Room‚Äù means the Flywheel‚Äôs gated staging directory (e.g., _waiting_room/ in a Hugging Face repository) where Contributions are first written prior to validation and release.\n‚ÄúRelease‚Äù means a published version of the dataset (and associated notes/checksums) assembled from validated Contributions, partitioned by License.\n‚ÄúGated Repository‚Äù means the Hugging Face dataset repository that requires an access request and acceptance of dataset-specific terms.\n‚ÄúStatic Site‚Äù means the public site that hosts leaderboards and provides full dataset access, with anti-scraping controls.\n‚ÄúAnonymized Contributor ID‚Äù or ‚ÄúPseudonym‚Äù means a non-identifying handle published with a Contribution when a contributor elects anonymity or a pseudonym instead of a Hugging Face username.\n‚ÄúPersonal Data‚Äù means information that identifies or can reasonably be linked to an individual; ‚ÄúSensitive Personal Data‚Äù means Personal Data that is sensitive by law or policy (e.g., health, financial, precise location, government identifiers).\n‚ÄúWe/Us/Our‚Äù means [ENTITY NAME], the operator of the Frontend, the Open WebUI Instance, and the Flywheel.\n‚ÄúYou/Your‚Äù means the individual using the Frontend and/or contributing to the Flywheel, or the entity on whose behalf the individual acts.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "03data_policy.html#system-scope-components",
    "href": "03data_policy.html#system-scope-components",
    "title": "3¬† Data Flow and Data Retention",
    "section": "4.1 1) System scope & components",
    "text": "4.1 1) System scope & components\n\nModel Endpoints (National Labs/Providers): Third-party endpoints; {The Public AI Chat Frontend} is a gateway.\nHosted Open WebUI: Browser interface for issuing prompts to supported models; optional user accounts.\nOpt-in Data Flywheel: Contributors may donate prompt/response pairs plus optional metadata for evaluation and research.\nDistribution Channels\n\nHugging Face (gated): Live view into dataset; access requires request and acceptance of terms.\nFlywheel Static Site (public): Leaderboards and full dataset access for benchmarking; protected with Cloudflare anti-scraping controls.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "03data_policy.html#what-data-is-produced-when",
    "href": "03data_policy.html#what-data-is-produced-when",
    "title": "3¬† Data Flow and Data Retention",
    "section": "4.2 2) What data is produced & when",
    "text": "4.2 2) What data is produced & when\n\n4.2.1 2.1 Open WebUI (no account required, but optional and recommended)\n\nSession telemetry (minimal) #todo: Double check telemetry and provide a sample paylod to show interested users;\n\nProduced when: Page load / navigation\nIncludes: Timestamp, pseudonymous session ID, coarse locale, feature flags\nStored in: First-party analytics\nAccess: Eng/Analytics (aggregated)\nDefault retention: Raw 30 days; aggregates 13 months\n\nIP & User-Agent (security) #todo double check this\n\nProduced when: Each request\nIncludes: IP, User-Agent for rate-limit/abuse detection\nStored in: Security log store\nAccess: SRE/Security\nDefault retention: 7 days, then delete/aggregate\n\nQuery content\n\nProduced when: On submit\nIncludes: Prompt + output\nStored in: interface database\nAccess: server admin only\nDefault retention: user can delete at any time; deleted along after 30 days of user inactivity. #todo, discuss this\n\nError logs (sanitized) #todo double check this, provide example? least important to provide an example here.\n\nProduced when: On error\nIncludes: Stack trace, request ID (no prompt/output bodies)\nStored in: Log store\nAccess: Eng (least privilege)\nDefault retention: 30 days\n\n\n\n\n4.2.2 2.2 Open WebUI Accounts (optional)\n\nProfile and settings #todo double check this\n\nProduced when: Sign-up\nIncludes: Email/OAuth ID, display name\nStored in: User DB\nAccess: Support/Eng\nRetention: Kept until the user deletes it. If the account is inactive for 30 days, we delete the account and associated records.\n\n\n\n\n4.2.3 2.3 Model Gateway (to providers)\n\nRequest envelope\n\nProduced when: Each request\nIncludes: Request ID, model ID, token counts, latency, status\nStored in: Metrics DB\nAccess: Eng/SRE\nRetention: 90 days (aggregates 13 months)\n\n\n\nProvider transparency: We do not guarantee provider behavior. We clearly display the exact payload we forward (headers + body summary) and link to the provider‚Äôs own terms and policies where available. Users should review provider terms before use.\n\n\n\n4.2.4 2.4 Opt-in Data Flywheel\n\nContribution payload\n\nProduced when: On explicit opt-in\nIncludes: Prompt, model output, optional tags\nStored in: Gated staging (effectively public) ‚Üí license-bucketed release (also effectively public)\nAccess: Public\nRetention: Indefinite\n\nHuggingFace username OR Anonymized contributor ID\n\nProduced when: On ingest\nIncludes: user provides their huggingface username or selects a pseudonym (can leave blank)\nStored in: Dataset metadata\nAccess: Public\nRetention: Indefinite\n\nRelease artifacts\n\nProduced when: On release\nIncludes: JSONL/TSV, checksums, notes\nStored in: HF (gated) and Static Site (public)\nAccess: Public (per channel)\nRetention: Indefinite",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "03data_policy.html#event-timeline-how-data-flows",
    "href": "03data_policy.html#event-timeline-how-data-flows",
    "title": "3¬† Data Flow and Data Retention",
    "section": "4.3 3) Event timeline (how data flows)",
    "text": "4.3 3) Event timeline (how data flows)\n\nUser prompts a model ‚Üí payload sent to model provider; query and response are saved if user made an optional OpenWebUI account.\nIf user wishes to select a chat to share via opt-in, they can do so. They never have to. Licensing and preference signals are set at opt-in time.\nOpt-in chat goes to ‚Äúwaiting room‚Äù\nProcessing script collects items from waiting room, applies some checks (PII, content moderation), moves them into release buckets.\nA separate processing script takes data from the gated HF repo and builds the static site with leaderboard and data dump\nPost-release: approved removals are honored in future releases and our mirrors; prior downloads may persist.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "03data_policy.html#licensing-preference-signals-beta",
    "href": "03data_policy.html#licensing-preference-signals-beta",
    "title": "3¬† Data Flow and Data Retention",
    "section": "4.4 4) Licensing & Preference Signals (Beta)",
    "text": "4.4 4) Licensing & Preference Signals (Beta)\nFor each contribution, the user selects:\n\nA Creative Commons license: CC0-1.0, CC-BY-4.0, or CC-BY-SA-4.0.\nAn AI preference signal: an IETF AI preference (draft) value and/or CC preference signal (‚ÄúIETF AI Pref combo‚Äù).\n\nHow we use these:\n\nWe record license and ai_pref per record.\nRecords are partitioned by license into separate release buckets.\nDownstream users must comply with the license; we publish compatibility notes (e.g., ShareAlike).\nUsers may set account defaults; each submission can override.\n\nBinding effect: Once a record is included in a release, that license applies to that copy.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "03data_policy.html#retention-schedule",
    "href": "03data_policy.html#retention-schedule",
    "title": "3¬† Data Flow and Data Retention",
    "section": "4.5 5) Retention schedule",
    "text": "4.5 5) Retention schedule\n\nWeb edge\n\nData: IP + UA\nPurpose: Abuse prevention\nRetention: 7 days raw ‚Üí delete/aggregate\nDeletion path: Automatic purge\n\nWeb UI\n\nData: Minimal telemetry\nPurpose: Reliability metrics\nRetention: 7 days raw ‚Üí delete/aggregate\nDeletion path: Automatic purge\n\nGateway\n\nData: Request envelopes\nPurpose: Capacity/SLOs\nRetention: 90 days raw; 13 months aggregates\nDeletion path: Automatic purge\n\nOpen WebUI Accounts\n\nData: Profile and preferences\nPurpose: Auth/consent\nRetention: Kept until user deletes; 30-day inactivity ‚Üí delete\nDeletion path: Self-service delete / auto-purge\n\nFlywheel staging bucket (the ‚Äúwaiting room dir‚Äù, on HF)\n\nData: Pending contributions\nPurpose: Moderation/de-duplication\nRetention: Indefinite (moved to organized buckets in same repo)\nDeletion path: Manual removal on request\n\nHF (gated)\n\nData: Released records (by license)\nPurpose: Research access\nRetention: Indefinite\nDeletion path: Exclude from future versions; coordinate HF deletion where possible\n\nStatic Site (public)\n\nData: Leaderboards and full dataset access\nPurpose: Benchmarking/transparency\nRetention: Indefinite\nDeletion path: Update/remove in future releases; past downloads may persist",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "03data_policy.html#distribution-access-control",
    "href": "03data_policy.html#distribution-access-control",
    "title": "3¬† Data Flow and Data Retention",
    "section": "4.6 6) Distribution & access control",
    "text": "4.6 6) Distribution & access control\n\n4.6.1 6.1 Hugging Face (gated)\n\nSeparate artifacts and checksums per license bucket and version (e.g., v1.0-cc0, v1.0-cc-by, v1.0-cc-by-sa).\nAccess requires a request with acceptance of dataset-specific Terms of Use (no re-identification; honor license and AI preferences).\nDeletion requests: Where possible, we use Hugging Face‚Äìnative workflows (e.g., issue/repo requests, maintainers‚Äô takedowns) to process deletions and exclude items from future versions.\n\n\n\n4.6.2 6.2 Flywheel Static Site (public)\n\nHosts leaderboards and provides full dataset access for building benchmarks.\nCloudflare anti-scraping posture: Bot Management/WAF rules, rate limits, Turnstile/JS challenges on download routes, tokenized short-lived URLs, robots/meta controls, pagination/throttling, and anomaly monitoring.\nReality check: Anti-scraping reduces but cannot prevent copying of public data. We limit risk via license partitioning, logged access flows, and clear terms.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "03data_policy.html#provider-transparency-no-guarantees",
    "href": "03data_policy.html#provider-transparency-no-guarantees",
    "title": "3¬† Data Flow and Data Retention",
    "section": "4.7 7) Provider transparency (no guarantees)",
    "text": "4.7 7) Provider transparency (no guarantees)\n\nWe do not control third-party model providers‚Äô retention or training practices and make no guarantees about them.\nFor every request, we show users a payload transparency panel (headers summary + body size/tokens) and, where possible, a link to provider terms.\nUsers choose whether to proceed with the selected provider in light of those terms.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "03data_policy.html#contributor-rights-controls",
    "href": "03data_policy.html#contributor-rights-controls",
    "title": "3¬† Data Flow and Data Retention",
    "section": "4.8 8) Contributor rights & controls",
    "text": "4.8 8) Contributor rights & controls\n\nOpt-in only for contributions to the flywheel.\nPer-item license and AI preference (beta).\nWithdrawals: Submit a verified request to exclude your items from future releases. We‚Äôll also file/route requests through Hugging Face where applicable.\nAccount deletion & inactivity: If you keep an Open WebUI account, we keep your account data until you delete it; if you are inactive for 30 days, we delete the account and associated records. Released dataset copies remain under their chosen licenses.\nSensitive content: Do not submit personal/sensitive data; automated filters and moderation apply.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "03data_policy.html#roadmap",
    "href": "03data_policy.html#roadmap",
    "title": "3¬† Data Flow and Data Retention",
    "section": "4.9 9) Roadmap",
    "text": "4.9 9) Roadmap\n\nHF-auth contributions: Let contributors submit via their Hugging Face accounts to preserve reputation and contributor stats.\nAI preference UX: First-class UI for selecting license + IETF AI Pref combo, plus validator and compatibility helper.\nProvider term links directory: Central index of provider policies; per-model tooltips in the WebUI.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "03data_policy.html#contacts",
    "href": "03data_policy.html#contacts",
    "title": "3¬† Data Flow and Data Retention",
    "section": "4.10 10) Contacts",
    "text": "4.10 10) Contacts\n#todo\n\nData removal / privacy: {{PRIVACY_EMAIL}}\nSecurity: {{SECURITY_EMAIL}}\nResearch & benchmarks: {{RESEARCH_EMAIL}}",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Flow and Data Retention</span>"
    ]
  },
  {
    "objectID": "04options_for_flywheel.html",
    "href": "04options_for_flywheel.html",
    "title": "4¬† Rationale (and other flywheel variants)",
    "section": "",
    "text": "4.1 Purpose of this section\nThis section explains the why behind {The Public AI Chat Frontend}‚Äôs data and distribution design, and lays out alternative governance paths and a future work (in particular, a focus on futures that involve healthy data markets, data intermediaries, federated learning, etc.)\nWe also discuss why we think an approach that includes a minimal retention frontend + opt-in flyhweel platform can serve as a pragmatic bridge to future models: e.g., we can use the concepts used here to move towards independently governed data co-ops, eventual **federated learning, etc.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rationale (and other flywheel variants)</span>"
    ]
  },
  {
    "objectID": "04options_for_flywheel.html#more-on-all-the-other-approaches-we-couldve-taken",
    "href": "04options_for_flywheel.html#more-on-all-the-other-approaches-we-couldve-taken",
    "title": "4¬† Rationale (and other flywheel variants)",
    "section": "4.2 More on all the other approaches we could‚Äôve taken",
    "text": "4.2 More on all the other approaches we could‚Äôve taken\nIn choosing our architecture, we consider the following questions:\n\n4.2.1 Where does the ‚Äúfinal‚Äù data live?\n\nCentralized Database: Traditional server-controlled storage (PostgreSQL, MongoDB, etc.)\nPublic Repository: Version-controlled platforms (GitHub, GitLab, Hugging Face Hub)\nDistributed Network: Peer-to-peer systems (IPFS, BitTorrent)\nTotally Local: Federated model where data stays on user devices\nSomething hybrid?: Metadata centralized, actual data distributed\n\n\n\n4.2.2 When is the user prompted to contribute?\n\nProactive: User initiates contribution unprompted (e.g., ‚ÄúShare this chat‚Äù button)\nReactive: System prompts based on signals (e.g., after thumbs down, ask ‚ÄúWhat went wrong?‚Äù)\nPassive: Automatic collection with prior consent (e.g., telemetry, browser extension)\nScheduled: Regular prompts (e.g., weekly ‚Äúbest conversations‚Äù review)\nTask-Based: Specific requests for data types (e.g., ‚ÄúHelp us improve math responses‚Äù)\n\n\n\n4.2.3 What information object is created?\n\nSimple Signal: Binary feedback (üëç/üëé), star ratings, or flags\nAnnotated Conversation: Full chat with user corrections, ratings, or notes\nPreference Pair: A/B comparisons between responses\nSynthetic Example: User-created prompts and ideal responses\nStructured Feedback: Form-based input (error type, severity, correction)\nMultimodal Bundle: Text + images + voice + metadata\nMore advanced structure data ‚Ä¶\n\n\n\n4.2.4 When is the data processed?\n\nPre-submission: Client-side processing before data leaves user‚Äôs device\nOn-submission: Real-time processing during the contribution flow\nPost-submission: Batch processing after data is received\nPre-publication: Review and processing before making data public\nOn-demand: Processing happens when data is accessed/downloaded\n\n(In practice, there may be some processing at various steps, but it is important to clarify this to users)\n\n\n4.2.5 How is the data accessed?\n\nDirect Download: Raw access to complete dataset (with rate limits)\nAPI Access: Programmatic access with authentication and quotas\nStatic Site: Read-only web interface with anti-scraping measures\nGated Access: Application/approval process for researchers\nHybrid Access: Public samples + gated full access, or public metadata + restricted content\nStreaming Access: Real-time feeds for continuous model training\n\n\n\n4.2.6 How much friction is acceptable?\n\nZero-Friction: One-click actions with no interruption\nLow-Friction: Modal popup or inline form\nMedium-Friction: Redirect to separate interface\nHigh-Friction: Multi-step process, account creation, or technical skills required",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rationale (and other flywheel variants)</span>"
    ]
  },
  {
    "objectID": "04options_for_flywheel.html#some-categories-of-architectural-models",
    "href": "04options_for_flywheel.html#some-categories-of-architectural-models",
    "title": "4¬† Rationale (and other flywheel variants)",
    "section": "4.3 Some Categories of Architectural Models",
    "text": "4.3 Some Categories of Architectural Models\n\n4.3.1 Standard ‚ÄúPrivateCo‚Äù Web App\nAn obvious option is to simply build a hosted ‚Äústandard‚Äù ‚ÄúPrivateCo‚Äù /start-up style web app. In fact, in some contexts it may make sense to skip building an opt-in flyhweel and simply use the data generated by users directly for training, eval, etc. While one could argue that the Terms of Service for many existing tech products do make these products ‚Äúopt in‚Äù in some sense, there are also serious downsides to the status quo (see e.g.¬†Fiesler, Lampe, and Bruckman 2016.)\nWhile perhaps some users might prefer even prefer a start-up style model, we believe this would not be a good starting place for a public AI interface. We also believe it‚Äôs important to communicate to users how the public AI interface differs from e.g.¬†using ChatGPT, Gemini, or AI overviews via search.\nHow this approach answers the above questions:\n\nWhere data lives: Centralized database\nWhen prompted: Proactive (user initiates)\nInformation object: Annotated conversations with structured feedback\nWhen processed: On-submission + pre-publication review\nHow accessed: API + static site with rate limits\nFriction level: Medium (redirect to platform)\nPros: Full control over UX, rich features, easy user management\nCons: High maintenance, single point of failure, trust requirements\nExample Stack: Django/Rails + PostgreSQL, Next.js + MongoDB\n\n\n\n4.3.2 Git/Wiki Platform\n\nWhere data lives: Public repository\nWhen prompted: Proactive (user initiates)\nInformation object: Markdown-formatted conversations\nWhen processed: Pre-submission (user does it) + CI/CD validation\nHow accessed: Direct download via Git + web interface\nFriction level: High (technical knowledge required)\nPros: Maximum transparency, built-in versioning, low cost\nCons: Excludes non-technical users, limited data types\nExample Stack: GitHub/GitLab + CI/CD validation\n\n\n\n4.3.3 Direct Telemetry\n\nWhere data lives: Centralized analytics database\nWhen prompted: Passive (continuous collection)\nInformation object: Simple signals with context IDs\nWhen processed: On-submission (real-time pipeline)\nHow accessed: Aggregated dashboards only (no raw access)\nFriction level: Zero\nPros: Massive scale, unbiased sampling, real-time insights\nCons: Limited richness, privacy concerns, no corrections\nExample Stack: ClickHouse/BigQuery + streaming pipeline\n\n\n\n4.3.4 Hybrid Model\n\nWhere data lives: Centralized database\nWhen prompted: Reactive (triggered by signals)\nInformation object: Signals + optional full conversations\nWhen processed: Signals processed immediately, conversations reviewed\nHow accessed: Public aggregates + gated conversation access\nFriction level: Zero, then low\nPros: Balances volume and quality, efficient targeting\nCons: Complex implementation, two-system maintenance\nExample Stack: Telemetry backend + web app frontend\n\n\n\n4.3.5 Serverless + Git Platform\n\nWhere data lives: Public repository\nWhen prompted: Proactive or reactive\nInformation object: Structured data files (JSON/YAML)\nWhen processed: On-submission via serverless function\nHow accessed: Git access + static site generation\nFriction level: Low (automated complexity)\nPros: Transparency + usability, serverless scaling\nCons: Cold starts, API rate limits, complex error handling\nExample Stack: Vercel/Netlify + GitHub API + Hugging Face Hub\n\n\n\n4.3.6 Federated Learning Model\n\nWhere data lives: User devices (distributed)\nWhen prompted: Passive with consent\nInformation object: Model gradients or aggregated statistics\nWhen processed: Pre-submission (on-device)\nHow accessed: Only aggregated model updates available\nFriction level: Zero after setup\nPros: Maximum privacy, no data transfer, infinite scale\nCons: Complex implementation, limited debugging, device requirements\nExample Stack: Flower/TFF + edge deployment\n\n\n\n4.3.7 Browser Extension (just a data ingestion choice: can be used with various backend choices above)\n\nWhere data lives: Centralized or distributed\nWhen prompted: Proactive or passive\nInformation object: DOM captures, interaction logs, selections\nWhen processed: Pre-submission (client-side) + server validation\nHow accessed: Depends on storage choice\nFriction level: Low after installation\nPros: Cross-platform, rich context, works anywhere\nCons: Browser-specific development, installation barrier\nExample Stack: WebExtensions API + backend API\n\n\n\n4.3.8 P2P Network Model\n\nWhere data lives: Distributed across peer nodes\nWhen prompted: Passive (background sharing)\nInformation object: Torrent-style data chunks\nWhen processed: Pre-submission by contributor + network validation\nHow accessed: P2P client required for full access\nFriction level: Medium (client installation)\nPros: No infrastructure costs, censorship resistant\nCons: Availability issues, complex coordination\nExample Stack: libp2p + BitTorrent protocol + DHT",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rationale (and other flywheel variants)</span>"
    ]
  },
  {
    "objectID": "04options_for_flywheel.html#terse-decision-matrix-for-the-above-dimensions",
    "href": "04options_for_flywheel.html#terse-decision-matrix-for-the-above-dimensions",
    "title": "4¬† Rationale (and other flywheel variants)",
    "section": "4.4 Terse decision Matrix for the above dimensions",
    "text": "4.4 Terse decision Matrix for the above dimensions\n\n\n\n\n\n\n\n\n\n\n\n\n\nArchitecture\nData Location\nPrompt Timing\nObject Complexity\nProcessing Stage\nAccess Method\nFriction\nBest For\n\n\n\n\nWeb App\nCentralized\nProactive\nHigh\nOn-submission\nAPI + Static\nMedium\nFull-featured contributions\n\n\nGit/Wiki\nPublic repo\nProactive\nMedium\nPre-submission\nDirect Git\nHigh\nTechnical community\n\n\nTelemetry\nCentralized\nPassive\nLow\nReal-time\nAggregated only\nZero\nLarge-scale signals\n\n\nHybrid\nCentralized\nReactive\nVariable\nMixed\nTiered access\nVariable\nBalanced approach\n\n\nServerless+Git\nPublic repo\nProactive\nHigh\nOn-submission\nGit + Static\nLow\nTransparency + usability\n\n\nFederated\nDistributed\nPassive\nLow\nOn-device\nModel updates only\nZero\nPrivacy-first\n\n\nExtension\nVariable\nVariable\nHigh\nClient + server\nVariable\nLow\nCross-platform capture\n\n\nP2P\nDistributed\nPassive\nMedium\nPre + network\nP2P client\nMedium\nDecentralized commons",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rationale (and other flywheel variants)</span>"
    ]
  },
  {
    "objectID": "04options_for_flywheel.html#scenario-walkthroughs-a-practical-comparison",
    "href": "04options_for_flywheel.html#scenario-walkthroughs-a-practical-comparison",
    "title": "4¬† Rationale (and other flywheel variants)",
    "section": "4.5 Scenario Walkthroughs: A Practical Comparison",
    "text": "4.5 Scenario Walkthroughs: A Practical Comparison\nHere, we walk through two common scenarios and describe what happens (in one sentence) for each of the architectures described above.\n#todo: these could be made crisper to highlight the key differences better (But also be honest about where there are similarities)\n\n4.5.1 Scenario A: User marks a chat as ‚ÄúGood‚Äù ‚Äì when does processing happen?\n\nWeb App: Redirects to platform, PII scrubbed on submission, available via API after review\nGit/Wiki: User removes PII manually, creates PR, instantly visible on merge\nTelemetry: Signal sent, processed in real-time, only visible in aggregates\nHybrid: Signal sent immediately, full chat processed if shared\nServerless+Git: Modal appears, serverless function strips PII, PR created automatically\nFederated: Local processing only, contributes to next model update\nExtension: Captures state, removes PII client-side, sends to chosen backend\nP2P: Processes locally, shares with peers who validate before propagating\n\n\n\n4.5.2 Scenario B: User corrects a factual error\n\nWeb App: Editor interface, toxicity check on submission, published after human review\nGit/Wiki: User edits markdown, CI/CD checks format, visible immediately on merge\nTelemetry: Only captures ‚Äúerror‚Äù signal, no correction possible\nHybrid: Error signal triggers correction UI, correction queued for review\nServerless+Git: Inline correction, automated PII/toxicity checks, PR needs approval\nFederated: Correction processed locally, differential privacy applied\nExtension: Highlights error, pre-processes correction, sends to backend\nP2P: Broadcasts correction, network consensus before acceptance\n\n\n\n4.5.3 Scenario C: Accessing the contributed data\n\nWeb App: Researchers apply for API key, public sees samples on static site\nGit/Wiki: Anyone can clone repo, but rate-limited through CDN\nTelemetry: Only aggregated statistics available via public dashboard\nHybrid: Public can see signals dashboard, researchers apply for conversation access\nServerless+Git: Public (or gated) repo with all data, static site with search/filter\nFederated: No direct data access, only model checkpoints released\nExtension: Depends on backend choice, typically follows that model\nP2P: Must run client to access network, can specify data sharing preferences",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rationale (and other flywheel variants)</span>"
    ]
  },
  {
    "objectID": "04options_for_flywheel.html#frontier-approaches-data-cooperatives-federated-learning-and-more",
    "href": "04options_for_flywheel.html#frontier-approaches-data-cooperatives-federated-learning-and-more",
    "title": "4¬† Rationale (and other flywheel variants)",
    "section": "4.6 Frontier approaches data cooperatives, federated learning, and more",
    "text": "4.6 Frontier approaches data cooperatives, federated learning, and more\nIn many cases, users may want to have data governed by community organizations (e.g., organized by domain/region/language) that hold rights and decide release cadence, licensing defaults, and benefit policies.\nWe note that because our implementation is built on top of open-source software, communities can easily choose to deploy their own OpenWebUI instance and their own data flywheel and effectively operate entirely parallel, self-governed instances. If they also choose to share opt-in data via similar licensing and preference signal approaches, such datasets could be easily merged ‚Äì but with fine-grained adjustments to precise details (e.g., slight modifications on retention, access, release cadence, content moderation, adn so on.) Of course, data co-ops may choose to use quite different technical stacks. This approach is just one among many.\nIt may be possible to also move from an opt-in data flywheel approach to a federated learning-first approach. Here, model training occurs across user or institutional nodes; only gradients/updates (with privacy tech) are centralized. The dataset remains partitioned or local; central custodian minimized. This approach would:\n\nReduces central data custody and breach surface\nAligns with data-residency and institutional constraints\nEnables ‚Äúlearning from data that can‚Äôt leave‚Äù\n\nBut has some major downsides / existing barriers:\n\nHarder reproducibility and data auditability\nComplex privacy stack (secure aggregation, DP, client attestation)\nBenchmarking must be redesigned (federated eval)\n\nThis is a bigger leap, but we believe it‚Äôs important to begin to think about how the implementation of the Public AI Data Flywheels might support communities wishing to transition towards an FL approach.\nOne rough sketch might look like: * Build the MVP defined in Chapter 2 * Ship license + AI-preference metadata (MVP). * Maintain gated HF releases and public leaderboards/full data access. * Publish provider-payload transparency and link to provider terms (no guarantees). * Process deletions via HF mechanisms when possible; keep our mirrors in sync. * Phase 1 ‚Äî Co-op pilots * Charter one or two community co-ops; define bylaws, scope, and release cadence. * Spin up many instances of interface + flywheel combos (can fork software directly, or use similar approaches) * Establish a concrete sharing / merging plan * And beyond! * Once several independent data communities, are operated, it might be possible to move from lightweight sharing and merging to more serious federation with technical guarantees. Perhaps this might start with federated evaluation and then move to federated training. Much more to do here, out of scope for this document.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rationale (and other flywheel variants)</span>"
    ]
  },
  {
    "objectID": "appendix1_llm_data.html",
    "href": "appendix1_llm_data.html",
    "title": "5¬† Appendix 1: LLM Data Schemas",
    "section": "",
    "text": "Here, we describe many variants of LLM data. This will be relevant for when we extend the flywheel to include more types of data, and especially shift towards promoting the sharing (via opt-in flywheels, but also via new market mechanisms) of richer ‚Äúcontent data‚Äù.\n\nOpen Web / Crawls\n\nWARC/WAT/WET\n\nWARC (container for HTTP request/response records) ‚Äî spec & overview: IIPC WARC 1.1; Library of Congress format note. (IIPC Community Resources, The Library of Congress)\nWAT (JSON metadata extracted from WARC) and WET (plain text extracted from HTML) ‚Äî Common Crawl guides. (Common Crawl, Common Crawl)\n\nC4 (Colossal Clean Crawled Corpus) ‚Äî TFDS catalog & generator code. Fields are essentially clean text segments with basic metadata. (TensorFlow, GitHub)\nThe Pile (22-source, mixed corpus) ‚Äî paper & HTML view. (arXiv, ar5iv)\n\nEncyclopedic / Books\n\nWikipedia XML dumps (page/revision XML; SQL tables for links) ‚Äî Meta-Wiki dump format; Wikipedia database download. (Meta, Wikipedia)\nProject Gutenberg\n\nBooks: plain text/HTML master formats; ePub/MOBI derived. (Project Gutenberg)\nCatalog schema: daily RDF/XML (also CSV) for metadata; offline catalogs. (Project Gutenberg)\n\n\nScientific / Legal\n\narXiv (Atom/OAI-PMH metadata; bulk & API) ‚Äî OAI-PMH + API docs; bulk metadata page. (info.arxiv.org, info.arxiv.org, info.arxiv.org)\nJATS XML (journal article tag suite) ‚Äî NISO standards; NLM JATS site. (niso.org, jats.nlm.nih.gov)\n\nCode\n\nBigCode ‚Äî The Stack / The Stack v2 (source files + license/provenance metadata; dedup variants) ‚Äî HF datasets, project docs, arXiv overview. (Hugging Face, Hugging Face, BigCode, arXiv)\n\nForums / Q&A / Social\n\nStack Exchange dumps (XML: Posts, Users, Comments, Votes, etc.) ‚Äî SE Meta/docs & Data Explorer. (Meta Stack Exchange, data.stackexchange.com)\nReddit\n\nAPI JSON schema ‚Äî official API docs & help. (Reddit, Reddit Help)\nPushshift (historical dumps; research dataset) ‚Äî site & paper. (pushshift.io, arXiv)\n\n\nInstruction / Conversations (Post-training SFT)\n\nOpenAI-style chat schema (role-tagged: system|user|assistant, plus tool calls) ‚Äî API reference. (OpenAI Platform)\nAlpaca (JSON prompts/instructions/outputs) ‚Äî Stanford post & repo; cleaned community set. (crfm.stanford.edu, GitHub, GitHub)\nDatabricks Dolly-15k (human-written instruction/response pairs) ‚Äî repo. (GitHub)\nOpenAssistant OASST1 (message-tree conversations with roles) ‚Äî HF dataset card. (Hugging Face)\n\nPreference / Feedback (RLHF & DPO)\n\nHH-RLHF (Anthropic helpful/harmless, JSONL pairs: chosen vs rejected) ‚Äî dataset repo readme. (GitHub)\nDPO format (prompt + preferred vs dispreferred response) ‚Äî DPO paper. (arXiv)\n\nMultimodal (for VLMs/ASR)\n\nLAION-5B / Re-LAION-5B (image‚Äìtext pairs with CLIP scores; links) ‚Äî LAION posts. (laion.ai, laion.ai)\nWhisper (weakly-supervised ASR; audio ‚Üí text pairs) ‚Äî paper & blog. (arXiv, OpenAI)\nHowTo100M (YouTube instructional video clips + narrations) ‚Äî project page & paper. (di.ens.fr, arXiv)\n\nMath-reasoning (often for post-training/eval)\n\nGSM8K (grade-school word problems; JSON) ‚Äî repo & HF dataset card. (GitHub, Hugging Face)\nMATH (competition problems with step-by-step solutions) ‚Äî paper & HF. (arXiv, Hugging Face)\n\nCommon storage containers\n\nJSON Lines / NDJSON ‚Äî jsonlines.org; ndjson spec. (jsonlines.org, GitHub)\nTFRecord ‚Äî TensorFlow tutorial. (TensorFlow)\nApache Parquet ‚Äî project site. (Apache Parquet)\n\n\n#todo check all refs",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Appendix 1: LLM Data Schemas</span>"
    ]
  },
  {
    "objectID": "appendix2_prefsig.html",
    "href": "appendix2_prefsig.html",
    "title": "6¬† Appendix 2 ‚Äî Preference Signals for AI Data Use (CC signals + IETF AI Preferences)",
    "section": "",
    "text": "#todo: improve the references here to specific lines of IETF draft and the CC Preference Signals FAQ\n\nWhat CC signals are A Creative Commons framework for reciprocal AI reuse: content stewards can allow specific machine uses if certain conditions are met (e.g., credit, contributions, openness). Overview & implementation notes. (homepage, implementation)\nFour proposed CC signals (v0.1)\n\nCredit (cc-cr) ‚Äî cite the dataset/collection; RAG-style outputs should link back when feasible.\nCredit + Direct Contribution (cc-cr-dc) ‚Äî proportional financial/in-kind support.\nCredit + Ecosystem Contribution (cc-cr-ec) ‚Äî contribute to broader commons.\nCredit + Open (cc-cr-op) ‚Äî release model/code/data to keep the chain open. Source (draft repo & posts). (GitHub, Creative Commons)\n\nIETF AI Preferences (aipref) ‚Äî the transport & vocabulary\n\nVocabulary: a machine-readable set of categories (e.g., ai-use, train-genai) and preferences (y = grant, n = deny) with exceptions. Drafts. (datatracker.ietf.org, IETF, IETF AI Preferences Working Group)\nAttachment: how to convey these preferences via HTTP Content-Usage header and robots.txt extensions. Drafts. (datatracker.ietf.org, IETF)\nStructured Fields: uses RFC-standardized HTTP structured field values. (datatracker.ietf.org, datatracker.ietf.org, rfc-editor.org)\nRobots Exclusion Protocol baseline. (datatracker.ietf.org, rfc-editor.org)\n\nPutting them together (content-usage expression)\n\nShape:\n&lt;category&gt;=&lt;y|n&gt;;exceptions=&lt;cc-signal&gt;\nExample in robots.txt (allow everything, but AI use denied unless Credit):\nUser-Agent: *\nContent-Usage: ai-use=n;exceptions=cc-cr\nAllow: /\nExample HTTP header (deny gen-AI training unless Credit + Ecosystem):\nContent-Usage: train-genai=n;exceptions=cc-cr-ec\n(Syntax and examples from CC & IETF drafts.) (Creative Commons, IETF)\n\nOperational notes (for this repo‚Äôs flywheel)\n\nPer-record fields to store: license (CC0/CC-BY/CC-BY-SA) and ai_pref (IETF aipref value + optional CC signal), plus optional attribution handle. (Aligns with CC write-ups & IETF drafts.) (Creative Commons, datatracker.ietf.org)\nPlacement:\n\nLocation-based signals via robots.txt for site/paths. (datatracker.ietf.org)\nUnit-based signals via HTTP Content-Usage on dataset files and API responses. (datatracker.ietf.org)\n\nInteroperability expectations: signals are normative preferences; adherence relies on ecosystem norms (similar to robots.txt & CC license culture). (Creative Commons)\n\nContext & momentum\n\nCC‚Äôs 2025 launch posts; IETF WG activity updates (e.g., IPTC note). (Creative Commons, Creative Commons, IPTC)\n\n\n\n#todo check all refs",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Appendix 2 ‚Äî Preference Signals for AI Data Use (CC signals + IETF AI Preferences)</span>"
    ]
  },
  {
    "objectID": "appendix3_example_legalterms.html",
    "href": "appendix3_example_legalterms.html",
    "title": "7¬† Appendix 3: Example Legal Terms",
    "section": "",
    "text": "7.1 Opt-in Data Flywheel ‚Äî Legal Terms (Draft)\nEffective: [DATE]\nThrough the Opt-in Data Flywheel, you may contribute chats, corrections, and related materials to build openly accessible evaluation sets and datasets.\nYou may participate only if you agree to these Opt-in Data Flywheel Legal Terms (the ‚ÄúTerms‚Äù). 1. Eligibility\nThe Flywheel is open to individuals who are the age of majority in their jurisdiction, or to younger participants with verified parental/guardian consent and supervision. You must also comply with Our Community Guidelines/Acceptable Use Policy ([LINK]). 2. Your Contributions; Licensing; AI Preferences\n2.1 Opt-in Only. Submitting to the Flywheel is purely voluntary and separate from using the Open WebUI Instance.\n2.2 License Grant (per item). For each Contribution, you select one License (CC0-1.0, CC-BY-4.0, or CC-BY-SA-4.0). You grant Us a non-exclusive, worldwide right to publish, reproduce, modify (solely for formatting, moderation, and aggregation), distribute, and sublicense the Contribution under the selected License. Once included in a Release, that License applies to that copy of the Contribution.\n2.3 AI Preference Signals. If you attach an AI Preference Signal, We will transmit and display it with the Contribution and document how Our systems interpret such signals. We cannot guarantee that downstream users or Providers will honor such signals.\n2.4 Assurances. You represent and warrant that (a) you have the necessary rights to your Contributions; (b) your Contributions do not infringe third-party rights; (c) you will not include Sensitive Personal Data; and (d) you will comply with Our Acceptable Use Policy. 3. Accounts; Attribution; Pseudonymity\n3.1 Auth. Contributions require authentication (e.g., Hugging Face OAuth). 3.2 Attribution. You may choose to publish under your Hugging Face username, under a pseudonym, or as ‚Äúanonymous.‚Äù 3.3 Leaderboards. We may publish contribution metrics (counts, languages, tags) with your chosen public handle. We will not publish your email address. 4. Processing; Waiting Room; Release\n4.1 Waiting Room. Submissions write to a staging directory. 4.2 Validation. We may run automated and human review for formatting, de-duplication, PII/safety checks, and License/AI-preference validation. 4.3 Release. Validated items are appended to License Buckets (e.g., vYYYY-MM) and published to a Gated Repository and mirrored to the Static Site. 5. Distribution; Access Control\n5.1 Gated Repository. Access requires acceptance of dataset-specific terms (e.g., no re-identification; respect License and AI preferences). 5.2 Static Site. Public access includes anti-scraping measures (WAF/bot management, rate limits, tokenized URLs). Copying cannot be fully prevented; rely on License controls for downstream obligations. 6. Deletions & Takedowns\n6.1 Future-Only Removal. Upon verified request, We will exclude the identified Contribution(s) from future Releases and update mirrors where feasible. Past Releases and third-party copies may persist. 6.2 Hugging Face Workflows. Where possible, We will route or honor takedowns via the Hugging Face repository‚Äôs native workflows. 7. Provider Transparency (No Guarantees)\nWe forward prompts to third-party Providers. We display a payload transparency panel and link to Provider terms when available. We do not control Provider retention, training, or other uses of data once sent to them. 8. Privacy; Retention\nRetention and access for telemetry, envelopes, accounts, staging, Releases, and the Static Site are governed by the Data Retention & Contribution Policy (Section 3). That Policy is incorporated by reference. 9. Communications\nBy creating an account or requesting repository access, you may receive administrative emails (e.g., access decisions, policy updates). 10. Disclaimers; Limitation of Liability; Indemnity\nTHE FLYWHEEL AND RELEASES ARE PROVIDED ‚ÄúAS IS.‚Äù TO THE MAXIMUM EXTENT PERMITTED BY LAW, WE DISCLAIM ALL WARRANTIES (INCLUDING MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT). WE WILL NOT BE LIABLE FOR INDIRECT, SPECIAL, INCIDENTAL, CONSEQUENTIAL, EXEMPLARY, OR PUNITIVE DAMAGES. Our aggregate liability under these Terms will not exceed USD $500 (or the maximum permitted by law if lower). You agree to indemnify Us for third-party claims arising from your Contributions or breach of these Terms. 11. Updates\nWe may update these Terms by posting a new effective date. Continued use after the effective date constitutes acceptance. 12. Termination\nWe may suspend or terminate access at any time. Contributions included in prior Releases remain available under their Licenses. 13. Governing Law; Venue\nThese Terms are governed by the laws of [LAW & VENUE], without regard to conflict-of-laws rules. Exclusive venue lies in the courts of [VENUE].",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Appendix 3: Example Legal Terms</span>"
    ]
  },
  {
    "objectID": "appendix3_example_legalterms.html#frontend-instance",
    "href": "appendix3_example_legalterms.html#frontend-instance",
    "title": "7¬† Appendix 3: Example Legal Terms",
    "section": "7.2 Frontend Instance",
    "text": "7.2 Frontend Instance\nOpen WebUI Instance ‚Äî Terms of Use (Draft)\nEffective: [DATE]\nThese Terms govern your use of Our hosted Open WebUI Instance at {{app_link}} (or successor URLs). 1. Eligibility; Community Rules\nThe service is available to individuals who are the age of majority in their jurisdiction, or younger participants with verified parental/guardian consent and supervision. You must follow Our Community Guidelines/Acceptable Use Policy ([LINK]). 2. Accounts; Content\n2.1 Accounts Optional. You may use OWUI without an account; certain features (history, settings, opt-in share flows) require an account. 2.2 Your Content. Prompts and outputs in your account are stored as Chat Objects to provide history and UX features. They are not used for training or evaluation by Us unless you explicitly opt in via the Flywheel. 2.3 Feedback Data. Thumbs, flags, and similar signals may be stored to improve product reliability and moderation and are handled per Section 3 (Retention Policy). 3. Provider Transparency\nOWUI forwards your prompts to third-party Providers. We display a payload transparency panel and, where available, links to Provider terms. We do not control Provider retention, training, or other uses of your data. 4. Privacy; Retention; Security\nRetention, deletion, and access controls for telemetry, Security Logs, Request Envelopes, account data, and error logs are governed by the Data Retention & Contribution Policy (Section 3), incorporated here by reference. 5. Sharing to the Flywheel\nSharing to the Flywheel is separate and requires explicit opt-in with per-item License and AI Preference Signal selections. See the Flywheel Terms. 6. Acceptable Use\nYou agree not to: (a) upload Sensitive Personal Data; (b) violate laws or third-party rights; (c) attempt to reverse engineer or abuse rate limits; (d) circumvent access controls; or (e) interfere with service integrity. 7. Communications\nIf you create an account, We may send administrative emails (e.g., login links, security alerts, policy updates). 8. Disclaimers; Limitation of Liability\nOWUI IS PROVIDED ‚ÄúAS IS.‚Äù TO THE MAXIMUM EXTENT PERMITTED BY LAW, WE DISCLAIM ALL WARRANTIES (INCLUDING MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT). WE WILL NOT BE LIABLE FOR INDIRECT, SPECIAL, INCIDENTAL, CONSEQUENTIAL, EXEMPLARY, OR PUNITIVE DAMAGES. Our aggregate liability will not exceed USD $500 (or the maximum permitted by law if lower). 9. Updates; Termination\nWe may update these Terms by posting a new effective date. Continued use after the effective date constitutes acceptance. We may suspend or terminate accounts for any reason, including AUP violations or security risk. 10. Governing Law; Venue\nThese Terms are governed by the laws of [LAW & VENUE], without regard to conflict-of-laws rules. Exclusive venue lies in the courts of [VENUE].",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Appendix 3: Example Legal Terms</span>"
    ]
  }
]